{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "QePXuJ4OSqx1"
      },
      "source": [
        "# Autoencoder test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount google drive"
      ],
      "metadata": {
        "id": "qpFFZuyuVVDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "05s64En_VQuU",
        "outputId": "a3430207-4978-44ba-971f-392dd690c2c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/datasets/UCSD_Anomaly_Dataset.v1p2/UCSDped1"
      ],
      "metadata": {
        "id": "m1b2fWzEVtBQ",
        "outputId": "a30a26d5-22e2-40a8-dada-8921a9cd0927",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test  Train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "o77i8_8ASqyB"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "XdYouK9zSqyE"
      },
      "outputs": [],
      "source": [
        "from os import listdir, getenv\n",
        "from os.path import isfile, join, isdir\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import shelve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "xTnGyq3lSqyI"
      },
      "source": [
        "Config for directory and parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "h25RGJWDSqyK"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "  DATASET_ROOT = r\"/content/drive/MyDrive/datasets/UCSD_Anomaly_Dataset.v1p2/UCSDped1\"\n",
        "  DATASET_PATH = join(DATASET_ROOT, r'Train')\n",
        "  SINGLE_TEST_PATH = join(DATASET_ROOT, r'Test', r'Test032')\n",
        "  BATCH_SIZE = 1\n",
        "  EPOCHS = 1\n",
        "  MODEL_PATH = r'/content/drive/MyDrive/datasets/model_lstm.hdf5'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "IQAQaHcrSqyN"
      },
      "source": [
        "Augment data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5A67QG6cSqyP"
      },
      "outputs": [],
      "source": [
        "def get_clips_by_stride(stride, frames_list, sequence_size):\n",
        "    \"\"\" For data augmenting purposes.\n",
        "    Parameters\n",
        "    ----------\n",
        "    stride : int\n",
        "        The desired distance between two consecutive frames\n",
        "    frames_list : list\n",
        "        A list of sorted frames of shape 256 X 256\n",
        "    sequence_size: int\n",
        "        The size of the desired LSTM sequence\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "        A list of clips , 10 frames each\n",
        "    \"\"\"\n",
        "    clips = []\n",
        "    sz = len(frames_list)\n",
        "    clip = np.zeros(shape=(sequence_size, 256, 256, 1))\n",
        "    cnt = 0\n",
        "    for start in range(0, stride):\n",
        "        for i in range(start, sz, stride):\n",
        "            clip[cnt, :, :, 0] = frames_list[i]\n",
        "            cnt = cnt + 1\n",
        "            if cnt == sequence_size:\n",
        "                clips.append(np.copy(clip))\n",
        "                cnt = 0\n",
        "    return clips"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_training_set():\n",
        "    \"\"\"\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "        A list of training sequences of shape (NUMBER_OF_SEQUENCES,SINGLE_SEQUENCE_SIZE,FRAME_WIDTH,FRAME_HEIGHT,1)\n",
        "    \"\"\"\n",
        "    #####################################\n",
        "    # cache = shelve.open(Config.CACHE_PATH)\n",
        "    # return cache[\"datasetLSTM\"]\n",
        "    #####################################\n",
        "    clips = []\n",
        "    # loop over the training folders (Train000,Train001,..)\n",
        "    for f in sorted(listdir(Config.DATASET_PATH)):\n",
        "        if isdir(join(Config.DATASET_PATH, f)):\n",
        "            all_frames = []\n",
        "            # loop over all the images in the folder (0.tif,1.tif,..,199.tif)\n",
        "            for c in sorted(listdir(join(Config.DATASET_PATH, f))):\n",
        "                if str(join(join(Config.DATASET_PATH, f), c))[-3:] == \"tif\":\n",
        "                    img = Image.open(join(join(Config.DATASET_PATH, f), c)).resize((256, 256))\n",
        "                    img = np.array(img, dtype=np.float32) / 256.0\n",
        "                    all_frames.append(img)\n",
        "            # get the 10-frames sequences from the list of images after applying data augmentation\n",
        "            for stride in range(1, 3):\n",
        "                clips.extend(get_clips_by_stride(stride=stride, frames_list=all_frames, sequence_size=10))\n",
        "    return clips"
      ],
      "metadata": {
        "id": "0FIyKCdmdg1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "GgkdhGBXSqyU"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras.layers import Conv2DTranspose, ConvLSTM2D, BatchNormalization, TimeDistributed, Conv2D, LayerNormalization\n",
        "from keras.models import Sequential, load_model\n",
        "\n",
        "def get_model(reload_model=True):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    reload_model : bool\n",
        "        Load saved model or retrain it\n",
        "    \"\"\"\n",
        "    if not reload_model:\n",
        "        return load_model(Config.MODEL_PATH,custom_objects={'LayerNormalization': LayerNormalization})\n",
        "    training_set = get_training_set()\n",
        "    training_set = np.array(training_set)\n",
        "    training_set = training_set.reshape(-1,10,256,256,1)\n",
        "    seq = Sequential()\n",
        "    seq.add(TimeDistributed(Conv2D(128, (11, 11), strides=4, padding=\"same\"), batch_input_shape=(None, 10, 256, 256, 1)))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2D(64, (5, 5), strides=2, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    # # # # #\n",
        "    seq.add(ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(ConvLSTM2D(32, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    # # # # #\n",
        "    seq.add(TimeDistributed(Conv2DTranspose(64, (5, 5), strides=2, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2DTranspose(128, (11, 11), strides=4, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2D(1, (11, 11), activation=\"sigmoid\", padding=\"same\")))\n",
        "    print(seq.summary())\n",
        "    seq.compile(loss='mse', optimizer=keras.optimizers.Adam(lr=1e-4, decay=1e-5, epsilon=1e-6))\n",
        "    seq.fit(training_set, training_set,\n",
        "            batch_size=Config.BATCH_SIZE, epochs=Config.EPOCHS, shuffle=False)\n",
        "    seq.save(Config.MODEL_PATH)\n",
        "    return seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ep3GdYFhSqyY"
      },
      "outputs": [],
      "source": [
        "def get_single_test():\n",
        "    sz = 200\n",
        "    test = np.zeros(shape=(sz, 256, 256, 1))\n",
        "    cnt = 0\n",
        "    for f in sorted(listdir(Config.SINGLE_TEST_PATH)):\n",
        "        if str(join(Config.SINGLE_TEST_PATH, f))[-3:] == \"tif\":\n",
        "            img = Image.open(join(Config.SINGLE_TEST_PATH, f)).resize((256, 256))\n",
        "            img = np.array(img, dtype=np.float32) / 256.0\n",
        "            test[cnt, :, :, 0] = img\n",
        "            cnt = cnt + 1\n",
        "    return test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "z5xugRmrSqya"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def evaluate():\n",
        "    model = get_model(True)\n",
        "    print(\"trained model\")\n",
        "    test = get_single_test()\n",
        "    print(test.shape)\n",
        "    sz = test.shape[0] - 10 + 1\n",
        "    sequences = np.zeros((sz, 10, 256, 256, 1))\n",
        "    # apply the sliding window technique to get the sequences\n",
        "    for i in range(0, sz):\n",
        "        clip = np.zeros((10, 256, 256, 1))\n",
        "        for j in range(0, 10):\n",
        "            clip[j] = test[i + j, :, :, :]\n",
        "        sequences[i] = clip\n",
        "\n",
        "    print(\"got data\")\n",
        "    # get the reconstruction cost of all the sequences\n",
        "    reconstructed_sequences = model.predict(sequences,batch_size=4)\n",
        "    sequences_reconstruction_cost = np.array([np.linalg.norm(np.subtract(sequences[i],reconstructed_sequences[i])) for i in range(0,sz)])\n",
        "    sa = (sequences_reconstruction_cost - np.min(sequences_reconstruction_cost)) / np.max(sequences_reconstruction_cost)\n",
        "    sr = 1.0 - sa\n",
        "\n",
        "    # plot the regularity scores\n",
        "    plt.plot(sr)\n",
        "    plt.ylabel('regularity score Sr(t)')\n",
        "    plt.xlabel('frame t')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "19EwC-FdSqyc",
        "outputId": "017f7bcc-856d-4f6c-bb43-4a0e4104c88a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " time_distributed (TimeDistr  (None, 10, 64, 64, 128)  15616     \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            " layer_normalization (LayerN  (None, 10, 64, 64, 128)  256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, 10, 32, 32, 64)   204864    \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " layer_normalization_1 (Laye  (None, 10, 32, 32, 64)   128       \n",
            " rNormalization)                                                 \n",
            "                                                                 \n",
            " conv_lstm2d (ConvLSTM2D)    (None, 10, 32, 32, 64)    295168    \n",
            "                                                                 \n",
            " layer_normalization_2 (Laye  (None, 10, 32, 32, 64)   128       \n",
            " rNormalization)                                                 \n",
            "                                                                 \n",
            " conv_lstm2d_1 (ConvLSTM2D)  (None, 10, 32, 32, 32)    110720    \n",
            "                                                                 \n",
            " layer_normalization_3 (Laye  (None, 10, 32, 32, 32)   64        \n",
            " rNormalization)                                                 \n",
            "                                                                 \n",
            " conv_lstm2d_2 (ConvLSTM2D)  (None, 10, 32, 32, 64)    221440    \n",
            "                                                                 \n",
            " layer_normalization_4 (Laye  (None, 10, 32, 32, 64)   128       \n",
            " rNormalization)                                                 \n",
            "                                                                 \n",
            " time_distributed_2 (TimeDis  (None, 10, 64, 64, 64)   102464    \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " layer_normalization_5 (Laye  (None, 10, 64, 64, 64)   128       \n",
            " rNormalization)                                                 \n",
            "                                                                 \n",
            " time_distributed_3 (TimeDis  (None, 10, 256, 256, 128  991360   \n",
            " tributed)                   )                                   \n",
            "                                                                 \n",
            " layer_normalization_6 (Laye  (None, 10, 256, 256, 128  256      \n",
            " rNormalization)             )                                   \n",
            "                                                                 \n",
            " time_distributed_4 (TimeDis  (None, 10, 256, 256, 1)  15489     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,958,209\n",
            "Trainable params: 1,958,209\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\users\\valsp\\source\\repos\\cs310-autoencoder-test\\venv\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "ename": "InternalError",
          "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20020\\469811255.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20020\\1807367980.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"trained model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_single_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20020\\2781924748.py\u001b[0m in \u001b[0;36mget_model\u001b[1;34m(reload_model)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mseq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mse'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     seq.fit(training_set, training_set,\n\u001b[1;32m---> 38\u001b[1;33m             batch_size=Config.BATCH_SIZE, epochs=Config.EPOCHS, shuffle=False)\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[0mseq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mseq\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\valsp\\source\\repos\\cs310-autoencoder-test\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\valsp\\source\\repos\\cs310-autoencoder-test\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
          ]
        }
      ],
      "source": [
        "evaluate()"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "a21b2f229a0c1f4557fd2861f4ff1f79fd2ee7bdfb913779ac62e88f3d1b2954"
    },
    "kernelspec": {
      "display_name": "PyCharm (cs310-autoencoder-test)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "cs310-autoencoder-test.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}